# RAG Agent Platform - Project Specification

## üìã Document Info

| | |
|--|--|
| **Version** | 2.0 |
| **Date** | December 2024 |
| **Author** | - |
| **Status** | Ready for Development |
| **Changes** | Added Fine-tuning Module + Text-to-SQL |

---

## üéØ Project Overview

| | |
|--|--|
| **Project Name** | RAG Agent Platform |
| **Type** | Domain-Agnostic RAG + Multi-Agent System |
| **Purpose** | Portfolio ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡∏á‡∏≤‡∏ô AI Developer |
| **Target Company** | Sciology (Mental Health/Scientific Research) |

### Key Differentiators

- **Domain-Agnostic**: ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô domain ‡∏î‡πâ‡∏ß‡∏¢ config file
- **Multi-Agent**: Pre-built agents ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö HR, Legal, Finance, Research
- **Multi-Project**: ‡πÅ‡∏¢‡∏Å knowledge base ‡∏ï‡∏≤‡∏° project
- **Text-to-SQL**: Query database ‡∏î‡πâ‡∏ß‡∏¢‡∏†‡∏≤‡∏©‡∏≤‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥ ‚≠ê NEW
- **Fine-tuning**: Train custom embeddings/models ‚≠ê NEW
- **Production-Ready**: User management, usage limits, monitoring

---

## üõ† Tech Stack

### Core Technologies

| Layer | Technology | Reason |
|-------|------------|--------|
| **Frontend** | SvelteKit (Static) | ‡πÄ‡∏£‡πá‡∏ß, ‡∏£‡∏ß‡∏° container ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö backend |
| **Backend** | FastAPI (Python) | Async, ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö AI/ML |
| **LLM Gateway** | LiteLLM (Library + Proxy) | Unified API, multi-provider, Admin UI |
| **Vector Store** | ChromaDB | Embedded, ‡∏á‡πà‡∏≤‡∏¢, lightweight |
| **Embeddings** | Sentence-transformers | Open-source, fine-tunable |
| **Agent Framework** | Custom + LangGraph | ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏≥‡πÄ‡∏≠‡∏á ‡πÅ‡∏•‡πâ‡∏ß upgrade |
| **Monitoring** | Prometheus | Metrics collection |
| **Database** | PostgreSQL | User data, conversations |

### NEW: Fine-tuning Stack

| Component | Technology | Purpose |
|-----------|------------|---------|
| **Training** | Hugging Face Transformers | Fine-tune models |
| **Optimization** | PEFT / LoRA | Efficient fine-tuning |
| **Tracking** | Weights & Biases (optional) | Experiment tracking |
| **Model Hub** | Hugging Face Hub | Store & share models |
| **Local Inference** | Ollama | Run fine-tuned models |

### NEW: Text-to-SQL Stack

| Component | Technology | Purpose |
|-----------|------------|---------|
| **SQL Generation** | LLM + Schema Context | Generate SQL from text |
| **DB Connectors** | SQLAlchemy | Connect to multiple DBs |
| **Query Execution** | Secure sandbox | Safe query execution |
| **Result Formatting** | Pandas | Format & visualize results |

### DevOps & Infrastructure

| Component | Technology |
|-----------|------------|
| **VPS** | Hetzner CX32 (EU) |
| **PaaS** | Coolify (self-hosted) |
| **CI/CD** | GitHub Actions |
| **Container** | Docker + Docker Compose |
| **SSL** | Let's Encrypt (auto via Coolify) |
| **Version Control** | GitHub |

---

## üí∞ Cost Breakdown

| Item | Cost/Month |
|------|------------|
| Hetzner CX32 (4 vCPU, 8GB RAM, 80GB SSD) | ‚Ç¨6.80 (~‡∏ø260) |
| Coolify | Free |
| GitHub Actions | Free (2,000 min) |
| LiteLLM | Free |
| Hugging Face Hub | Free (public models) |
| Weights & Biases | Free (100GB) |
| **Infrastructure Total** | **~‡∏ø260/month** |
| LLM API (OpenAI/Claude/Groq) | Pay-per-use |

### Server Specs

```
Hetzner CX32 (EU - Germany/Finland)
- 4 vCPU (Shared, Intel)
- 8 GB RAM
- 80 GB NVMe SSD
- 20 TB Traffic included
- ‚Ç¨6.80/month

For Fine-tuning (optional - use Colab/Kaggle):
- Google Colab Pro: $10/month (A100 GPU)
- Kaggle: Free (30h/week GPU)
```

---

## üèó Architecture

### High-Level Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Hetzner VPS (CX32)                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ
‚îÇ  ‚îÇ                        Coolify                             ‚îÇ‚îÇ
‚îÇ  ‚îÇ                                                            ‚îÇ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  App Container   ‚îÇ  ‚îÇ   LiteLLM    ‚îÇ  ‚îÇ  Prometheus  ‚îÇ ‚îÇ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ  ‚îÇ   Proxy      ‚îÇ  ‚îÇ              ‚îÇ ‚îÇ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇSvelte(static)‚îÇ ‚îÇ  ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ  ‚îÇ              ‚îÇ ‚îÇ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  ‚îÇ  ‚îÇ   ‚îÇAdmin ‚îÇ  ‚îÇ  ‚îÇ              ‚îÇ ‚îÇ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ  FastAPI   ‚îÇ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚ñ∂‚îÇ UI   ‚îÇ  ‚îÇ  ‚îÇ              ‚îÇ ‚îÇ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  ‚îÇ  ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ  ‚îÇ              ‚îÇ ‚îÇ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ  ChromaDB  ‚îÇ  ‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ              ‚îÇ ‚îÇ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  ‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ              ‚îÇ ‚îÇ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ PostgreSQL ‚îÇ  ‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ              ‚îÇ ‚îÇ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ                           ‚îÇ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                   ‚îÇ
          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
          ‚îÇ                        ‚îÇ                        ‚îÇ
          ‚ñº                        ‚ñº                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ    LLM APIs      ‚îÇ    ‚îÇ  Customer DBs    ‚îÇ    ‚îÇ  Hugging Face    ‚îÇ
‚îÇ OpenAI ‚îÇ Claude  ‚îÇ    ‚îÇ PostgreSQL,MySQL ‚îÇ    ‚îÇ  Hub (Models)    ‚îÇ
‚îÇ Groq   ‚îÇ Ollama  ‚îÇ    ‚îÇ MSSQL, MongoDB   ‚îÇ    ‚îÇ                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Data Flow: RAG + Text-to-SQL

```
User Query: "‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà ‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ policy ‡∏≠‡∏∞‡πÑ‡∏£‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö commission"
     ‚îÇ
     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Query Router   ‚îÇ  ‚Üê Classify: RAG / SQL / Both
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ         ‚îÇ
    ‚ñº         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  RAG  ‚îÇ ‚îÇ SQL   ‚îÇ
‚îÇPipeline‚îÇ ‚îÇPipeline‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ         ‚îÇ
    ‚ñº         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇChunks ‚îÇ ‚îÇQuery  ‚îÇ
‚îÇ+Scores‚îÇ ‚îÇResults‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ         ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   LLM Synthesis ‚îÇ  ‚Üê Combine results
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ    Response     ‚îÇ
‚îÇ "‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ô‡∏µ‡πâ ‚îÇ
‚îÇ  ‡∏ø1.2M ‡πÅ‡∏•‡∏∞...   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Fine-tuning Pipeline

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Fine-tuning Pipeline                         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ  1. Data Preparation                                            ‚îÇ
‚îÇ     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê             ‚îÇ
‚îÇ     ‚îÇ Raw Data ‚îÇ ‚îÄ‚îÄ‚ñ∂ ‚îÇ Process  ‚îÇ ‚îÄ‚îÄ‚ñ∂ ‚îÇ Dataset  ‚îÇ             ‚îÇ
‚îÇ     ‚îÇ (docs)   ‚îÇ     ‚îÇ & Clean  ‚îÇ     ‚îÇ (HF fmt) ‚îÇ             ‚îÇ
‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  2. Training                                                    ‚îÇ
‚îÇ     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê             ‚îÇ
‚îÇ     ‚îÇ Base     ‚îÇ ‚îÄ‚îÄ‚ñ∂ ‚îÇ Fine-tune‚îÇ ‚îÄ‚îÄ‚ñ∂ ‚îÇ Trained  ‚îÇ             ‚îÇ
‚îÇ     ‚îÇ Model    ‚îÇ     ‚îÇ (LoRA)   ‚îÇ     ‚îÇ Model    ‚îÇ             ‚îÇ
‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îÇ
‚îÇ                           ‚îÇ                                     ‚îÇ
‚îÇ                           ‚ñº                                     ‚îÇ
‚îÇ                      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                               ‚îÇ
‚îÇ                      ‚îÇ  W&B     ‚îÇ  ‚Üê Track metrics              ‚îÇ
‚îÇ                      ‚îÇ Logging  ‚îÇ                               ‚îÇ
‚îÇ                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                               ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  3. Deployment                                                  ‚îÇ
‚îÇ     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê             ‚îÇ
‚îÇ     ‚îÇ Trained  ‚îÇ ‚îÄ‚îÄ‚ñ∂ ‚îÇ Push to  ‚îÇ ‚îÄ‚îÄ‚ñ∂ ‚îÇ Use in   ‚îÇ             ‚îÇ
‚îÇ     ‚îÇ Model    ‚îÇ     ‚îÇ HF Hub   ‚îÇ     ‚îÇ Platform ‚îÇ             ‚îÇ
‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üì¶ Features Specification

### 1. User System

#### 1.1 Authentication
- [ ] User registration (email + password)
- [ ] User login / logout
- [ ] Password reset
- [ ] Session management (JWT)

#### 1.2 User Tiers

| Tier | Token Limit | Projects | Documents | Models | Rate Limit |
|------|-------------|----------|-----------|--------|------------|
| **Free** | 50K/month | 3 | 10 | GPT-3.5 | 5 req/min |
| **Pro** | 500K/month | 20 | 100 | GPT-4, Claude | 30 req/min |
| **Enterprise** | Unlimited | Unlimited | Unlimited | All + Custom | 100 req/min |

#### 1.3 User Settings
- [ ] Profile management
- [ ] Default model preference
- [ ] Notification settings
- [ ] API key management (for power users)

---

### 2. Project System

#### 2.1 Project Management
- [ ] Create / Edit / Delete projects
- [ ] Project naming & description
- [ ] Project icon/color selection
- [ ] Project archiving

#### 2.2 Project Components

| Component | Description |
|-----------|-------------|
| **Documents** | Isolated knowledge base per project |
| **Database Connections** | External DB for Text-to-SQL ‚≠ê NEW |
| **Conversations** | Chat history within project |
| **Agent** | Assigned agent for project |
| **Settings** | Model, temperature, custom prompts |
| **Members** | Share with team (optional) |

#### 2.3 Project Settings
- [ ] Select agent type
- [ ] Select LLM model
- [ ] Custom system prompt
- [ ] Temperature / Top-K settings
- [ ] Enable/disable features
- [ ] Database connection settings ‚≠ê NEW

---

### 3. Agent System

#### 3.1 Pre-built Agents

| Agent | Description | Tools |
|-------|-------------|-------|
| **General** | General-purpose assistant | RAG search, summarize |
| **HR** | HR policy & recruitment | Resume parser, policy RAG, skill matcher |
| **Legal** | Legal analysis & research | Contract analyzer, law search, case compare |
| **Finance** | Financial analysis | Financial calculator, report analyzer, **SQL query** ‚≠ê |
| **Research** | Research assistant | Paper search, citation finder |
| **Data Analyst** | Data analysis ‚≠ê NEW | **SQL query**, chart generator, data summary |

#### 3.2 Agent Configuration (YAML)

```yaml
agent:
  name: "Data Analyst"
  description: "‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞ query database"
  icon: "üìä"
  
persona:
  system_prompt: |
    ‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ô‡∏±‡∏Å‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡∏ä‡πà‡∏ß‡∏¢ query database ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•
    ‡∏™‡∏£‡πâ‡∏≤‡∏á SQL ‡∏ó‡∏µ‡πà‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢ ‡πÑ‡∏°‡πà DELETE ‡∏´‡∏£‡∏∑‡∏≠ UPDATE ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢

tools:
  - name: "sql_query"
    description: "Query database ‡∏î‡πâ‡∏ß‡∏¢ SQL"
    config:
      read_only: true
      max_rows: 1000
      timeout: 30
  - name: "chart_generator"
    description: "‡∏™‡∏£‡πâ‡∏≤‡∏á chart ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"
  - name: "rag_search"
    description: "‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£"

knowledge_base:
  sources:
    - type: "local"
      path: "./data/analytics/"
    - type: "database"
      connection: "${DB_CONNECTION}"
      
ui:
  suggested_prompts:
    - "‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà"
    - "‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢ Q1 vs Q2"
    - "Top 10 ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ã‡∏∑‡πâ‡∏≠‡πÄ‡∏¢‡∏≠‡∏∞‡∏™‡∏∏‡∏î"
```

#### 3.3 Agent Features
- [ ] Agent selector UI
- [ ] Agent thinking display (step-by-step)
- [ ] Tool execution visualization
- [ ] Custom agent creation via YAML

---

### 4. Chat System

#### 4.1 Core Chat Features
- [ ] Real-time streaming responses
- [ ] Markdown rendering
- [ ] Code syntax highlighting
- [ ] Message editing / regeneration
- [ ] Conversation branching

#### 4.2 Source Citations
- [ ] Display source documents
- [ ] Show page/section references
- [ ] Link to original document
- [ ] Confidence scores
- [ ] Show SQL query used ‚≠ê NEW

#### 4.3 Multi-Model Support
- [ ] Model selector dropdown
- [ ] Models: GPT-3.5, GPT-4, Claude, Llama, Ollama
- [ ] Custom fine-tuned models ‚≠ê NEW
- [ ] Per-conversation model switching
- [ ] Model comparison mode (A/B)

#### 4.4 Conversation Memory
- [ ] Conversation history persistence
- [ ] Context window management
- [ ] Conversation summarization (for long chats)

---

### 5. RAG System

#### 5.1 Document Processing
- [ ] Supported formats: PDF, DOCX, TXT, MD, CSV
- [ ] Automatic text extraction
- [ ] Smart chunking (semantic / recursive)
- [ ] Metadata extraction

#### 5.2 Vector Store
- [ ] ChromaDB integration
- [ ] Per-project collections
- [ ] Embedding model: multilingual-e5-base (or fine-tuned)
- [ ] Hybrid search (Dense + BM25)

#### 5.3 Retrieval Pipeline
- [ ] Query preprocessing
- [ ] Hybrid search (dense + sparse)
- [ ] Reciprocal Rank Fusion (RRF)
- [ ] Re-ranking (optional)
- [ ] Context assembly

#### 5.4 Debug Panel
- [ ] Show retrieved chunks
- [ ] Show relevance scores
- [ ] Show latency breakdown
- [ ] Show token usage

---

### 6. Text-to-SQL System ‚≠ê NEW

#### 6.1 Database Connections

| Database | Status | Connector |
|----------|--------|-----------|
| **PostgreSQL** | ‚úÖ Supported | psycopg2 |
| **MySQL** | ‚úÖ Supported | pymysql |
| **MariaDB** | ‚úÖ Supported | pymysql |
| **SQL Server** | ‚úÖ Supported | pyodbc |
| **SQLite** | ‚úÖ Supported | sqlite3 |
| **MongoDB** | üîú Future | pymongo |

#### 6.2 Connection Management
- [ ] Add database connection (encrypted credentials)
- [ ] Test connection
- [ ] Auto-discover schema
- [ ] Schema caching
- [ ] Connection pooling

#### 6.3 Schema Configuration

```yaml
database:
  name: "Sales Database"
  type: "postgresql"
  connection:
    host: "${DB_HOST}"
    port: 5432
    database: "sales_db"
    username: "${DB_USER}"
    password: "${DB_PASS}"  # Encrypted
    
schema:
  tables:
    - name: "orders"
      description: "‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ã‡∏∑‡πâ‡∏≠"
      columns:
        - name: "id"
          type: "integer"
          description: "‡∏£‡∏´‡∏±‡∏™‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ã‡∏∑‡πâ‡∏≠"
        - name: "customer_id"
          type: "integer"
          description: "‡∏£‡∏´‡∏±‡∏™‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤"
        - name: "amount"
          type: "decimal"
          description: "‡∏¢‡∏≠‡∏î‡∏£‡∏ß‡∏°"
        - name: "created_at"
          type: "timestamp"
          description: "‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏±‡πà‡∏á"
    
    - name: "customers"
      description: "‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤"
      columns:
        - name: "id"
          type: "integer"
        - name: "name"
          type: "varchar"
        - name: "email"
          type: "varchar"

  relationships:
    - from: "orders.customer_id"
      to: "customers.id"
      type: "many-to-one"
```

#### 6.4 SQL Generation Pipeline

```
User Query: "‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏°‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤"
     ‚îÇ
     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Schema Context  ‚îÇ  ‚Üê Include table/column descriptions
‚îÇ + Query         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  LLM Generate   ‚îÇ  ‚Üê Generate SQL
‚îÇ  SQL Query      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  SQL Validator  ‚îÇ  ‚Üê Check syntax, safety
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Execute (Safe)  ‚îÇ  ‚Üê Read-only, timeout, row limit
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Format Results  ‚îÇ  ‚Üê Table, chart, summary
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### 6.5 Safety Features
- [ ] Read-only mode (SELECT only)
- [ ] Query whitelist (no DROP, DELETE, UPDATE)
- [ ] Row limit (max 1000 rows)
- [ ] Timeout (30 seconds)
- [ ] Query cost estimation
- [ ] Parameterized queries (prevent SQL injection)
- [ ] Sensitive column masking (e.g., passwords)

#### 6.6 Result Visualization
- [ ] Auto-detect best visualization
- [ ] Table view (with pagination)
- [ ] Bar chart
- [ ] Line chart
- [ ] Pie chart
- [ ] Export to CSV/Excel

#### 6.7 Example Queries

| Natural Language | Generated SQL |
|------------------|---------------|
| "‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ô‡∏µ‡πâ" | `SELECT SUM(amount) FROM orders WHERE created_at >= '2024-12-01'` |
| "Top 5 ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤" | `SELECT c.name, SUM(o.amount) as total FROM orders o JOIN customers c ON o.customer_id = c.id GROUP BY c.id ORDER BY total DESC LIMIT 5` |
| "‡∏≠‡∏≠‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏Ç‡∏≠‡∏á John" | `SELECT * FROM orders WHERE customer_id = (SELECT id FROM customers WHERE name LIKE '%John%')` |

---

### 7. Fine-tuning Module ‚≠ê NEW

#### 7.1 Fine-tuning Options

| Type | Use Case | Difficulty | Time |
|------|----------|------------|------|
| **Embedding Fine-tune** | Improve retrieval ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö domain | ‚≠ê‚≠ê Medium | 1-2 hours |
| **Classifier Fine-tune** | Intent classification | ‚≠ê Easy | 30 min |
| **LLM Fine-tune (LoRA)** | Domain-specific responses | ‚≠ê‚≠ê‚≠ê Hard | 2-4 hours |

#### 7.2 Embedding Fine-tuning

**Purpose**: ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á retrieval quality ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö domain ‡πÄ‡∏â‡∏û‡∏≤‡∏∞

**Base Model**: `intfloat/multilingual-e5-base`

**Training Data Format**:
```json
{
  "query": "‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢‡∏•‡∏≤‡∏û‡∏±‡∏Å‡∏£‡πâ‡∏≠‡∏ô‡∏Å‡∏µ‡πà‡∏ß‡∏±‡∏ô",
  "positive": "‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏°‡∏µ‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡∏•‡∏≤‡∏û‡∏±‡∏Å‡∏£‡πâ‡∏≠‡∏ô‡∏õ‡∏µ‡∏•‡∏∞ 10 ‡∏ß‡∏±‡∏ô",
  "negative": "‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏á‡∏Å‡∏≤‡∏¢‡∏™‡∏∏‡∏†‡∏≤‡∏û"
}
```

**Training Script**:
```python
from sentence_transformers import SentenceTransformer, InputExample, losses
from torch.utils.data import DataLoader

# Load base model
model = SentenceTransformer('intfloat/multilingual-e5-base')

# Prepare training data
train_examples = [
    InputExample(texts=[q, pos, neg])
    for q, pos, neg in training_data
]

train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)
train_loss = losses.TripletLoss(model)

# Fine-tune
model.fit(
    train_objectives=[(train_dataloader, train_loss)],
    epochs=3,
    warmup_steps=100,
    output_path='./models/custom-e5-hr'
)

# Push to Hugging Face Hub
model.push_to_hub("username/custom-e5-hr")
```

#### 7.3 Intent Classifier Fine-tuning

**Purpose**: Classify query ‚Üí Agent/Tool

**Base Model**: `bert-base-multilingual-cased`

**Training Data Format**:
```json
[
  {"text": "‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢‡∏•‡∏≤‡∏õ‡πà‡∏ß‡∏¢", "label": "hr"},
  {"text": "‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏à‡πâ‡∏≤‡∏á", "label": "legal"},
  {"text": "‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ô‡∏µ‡πâ", "label": "finance"},
  {"text": "paper ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö AI", "label": "research"}
]
```

**Training Script**:
```python
from transformers import (
    AutoTokenizer, 
    AutoModelForSequenceClassification,
    TrainingArguments, 
    Trainer
)
from datasets import Dataset

# Load base model
model_name = "bert-base-multilingual-cased"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(
    model_name, 
    num_labels=5  # hr, legal, finance, research, general
)

# Prepare dataset
dataset = Dataset.from_list(training_data)
dataset = dataset.map(lambda x: tokenizer(x['text'], truncation=True, padding=True))

# Training arguments
training_args = TrainingArguments(
    output_dir="./models/intent-classifier",
    num_train_epochs=5,
    per_device_train_batch_size=16,
    evaluation_strategy="epoch",
    save_strategy="epoch",
    load_best_model_at_end=True,
    push_to_hub=True,
    hub_model_id="username/intent-classifier-th"
)

# Train
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=dataset,
    tokenizer=tokenizer
)
trainer.train()
```

#### 7.4 LLM Fine-tuning (LoRA)

**Purpose**: Fine-tune LLM ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö domain-specific responses

**Base Model**: `Qwen/Qwen2.5-7B-Instruct` ‡∏´‡∏£‡∏∑‡∏≠ `meta-llama/Llama-3.1-8B-Instruct`

**Training Data Format** (Instruction format):
```json
[
  {
    "instruction": "‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢ HR",
    "input": "‡∏•‡∏≤‡∏û‡∏±‡∏Å‡∏£‡πâ‡∏≠‡∏ô‡πÑ‡∏î‡πâ‡∏Å‡∏µ‡πà‡∏ß‡∏±‡∏ô",
    "output": "‡∏ï‡∏≤‡∏°‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó ‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏°‡∏µ‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡∏•‡∏≤‡∏û‡∏±‡∏Å‡∏£‡πâ‡∏≠‡∏ô‡∏õ‡∏µ‡∏•‡∏∞ 10 ‡∏ß‡∏±‡∏ô ‡πÇ‡∏î‡∏¢‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏à‡πâ‡∏á‡∏•‡πà‡∏ß‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 3 ‡∏ß‡∏±‡∏ô ‡πÅ‡∏•‡∏∞‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏≠‡∏ô‡∏∏‡∏°‡∏±‡∏ï‡∏¥‡∏à‡∏≤‡∏Å‡∏´‡∏±‡∏ß‡∏´‡∏ô‡πâ‡∏≤‡∏á‡∏≤‡∏ô"
  }
]
```

**Training with QLoRA** (Efficient fine-tuning):
```python
from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig
from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training
from trl import SFTTrainer

# Quantization config (4-bit)
bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype="float16",
)

# Load model with quantization
model = AutoModelForCausalLM.from_pretrained(
    "Qwen/Qwen2.5-7B-Instruct",
    quantization_config=bnb_config,
    device_map="auto"
)
tokenizer = AutoTokenizer.from_pretrained("Qwen/Qwen2.5-7B-Instruct")

# LoRA config
lora_config = LoraConfig(
    r=16,
    lora_alpha=32,
    target_modules=["q_proj", "v_proj"],
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM"
)

# Prepare model
model = prepare_model_for_kbit_training(model)
model = get_peft_model(model, lora_config)

# Train with SFTTrainer
trainer = SFTTrainer(
    model=model,
    train_dataset=dataset,
    tokenizer=tokenizer,
    max_seq_length=512,
    args=TrainingArguments(
        output_dir="./models/hr-assistant-lora",
        num_train_epochs=3,
        per_device_train_batch_size=4,
        gradient_accumulation_steps=4,
        learning_rate=2e-4,
        fp16=True,
        push_to_hub=True,
    )
)
trainer.train()

# Merge LoRA weights and push
merged_model = model.merge_and_unload()
merged_model.push_to_hub("username/hr-assistant-7b")
```

#### 7.5 Fine-tuning UI (Admin Panel)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Fine-tuning Dashboard                                         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ Create New Training Job                                 ‚îÇ   ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§   ‚îÇ
‚îÇ  ‚îÇ Type:  [Embedding ‚ñº]                                    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ Base Model: [multilingual-e5-base ‚ñº]                    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ Training Data: [Upload CSV] or [Select from Documents]  ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ Output Name: [custom-e5-hr________________]             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ                                        [Start Training] ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Training Jobs                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ Job ID    ‚îÇ Type      ‚îÇ Status    ‚îÇ Progress ‚îÇ Actions   ‚îÇ ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îÇ
‚îÇ  ‚îÇ job-001   ‚îÇ Embedding ‚îÇ Running   ‚îÇ ‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë 67% ‚îÇ [Stop]  ‚îÇ ‚îÇ
‚îÇ  ‚îÇ job-002   ‚îÇ Classifier‚îÇ Completed ‚îÇ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100%‚îÇ [Deploy]‚îÇ ‚îÇ
‚îÇ  ‚îÇ job-003   ‚îÇ LLM LoRA  ‚îÇ Queued    ‚îÇ ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0%  ‚îÇ [Cancel]‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Deployed Models                                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ Model Name          ‚îÇ Type      ‚îÇ Status ‚îÇ Actions       ‚îÇ ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îÇ
‚îÇ  ‚îÇ custom-e5-hr        ‚îÇ Embedding ‚îÇ Active ‚îÇ [Use] [Delete]‚îÇ ‚îÇ
‚îÇ  ‚îÇ intent-classifier-th‚îÇ Classifier‚îÇ Active ‚îÇ [Use] [Delete]‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### 7.6 Integration with Platform

```yaml
# Project config - use fine-tuned models
project:
  name: "HR Project"
  
embeddings:
  model: "username/custom-e5-hr"  # Fine-tuned model
  
classifier:
  model: "username/intent-classifier-th"  # Route queries
  
llm:
  model: "username/hr-assistant-7b"  # Via Ollama
  # OR
  model: "gpt-4"  # Via LiteLLM
```

---

### 8. Admin & Monitoring

#### 8.1 Admin Panel
- [ ] User management (view, edit, suspend)
- [ ] Usage overview (all users)
- [ ] System health dashboard
- [ ] Cost tracking
- [ ] Fine-tuning job management ‚≠ê NEW
- [ ] Database connection management ‚≠ê NEW

#### 8.2 Monitoring (Prometheus)
- [ ] Request latency
- [ ] Token usage per user
- [ ] Error rates
- [ ] RAG retrieval quality
- [ ] SQL query performance ‚≠ê NEW
- [ ] Fine-tuning job status ‚≠ê NEW

#### 8.3 Logging
- [ ] Request/response logs
- [ ] Error logs
- [ ] Audit logs (for enterprise)
- [ ] SQL query logs (with masking) ‚≠ê NEW

---

## üìÅ Project Structure (Updated)

```
rag-agent-platform/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ auth.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chat.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ projects.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ documents.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ agents.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ admin.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database.py          # ‚≠ê NEW: DB connections API
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ finetune.py          # ‚≠ê NEW: Fine-tuning API
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ security.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ llm_client.py
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ user.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ project.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ conversation.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ document.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ db_connection.py     # ‚≠ê NEW
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ finetune_job.py      # ‚≠ê NEW
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ rag/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ embeddings.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chunking.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ retriever.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ pipeline.py
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ agents/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ engine.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tools/
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ rag_search.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ summarize.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sql_query.py     # ‚≠ê NEW
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ chart_gen.py     # ‚≠ê NEW
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ prebuilt/
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ general.py
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ hr.py
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ legal.py
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ finance.py
‚îÇ   ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ data_analyst.py  # ‚≠ê NEW
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ text2sql/                # ‚≠ê NEW
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ schema.py            # Schema discovery
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ generator.py         # SQL generation
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ validator.py         # SQL validation
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ executor.py          # Safe execution
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ visualizer.py        # Result visualization
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ finetune/                # ‚≠ê NEW
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ embedding.py         # Embedding fine-tuning
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ classifier.py        # Classifier fine-tuning
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ llm_lora.py          # LLM LoRA fine-tuning
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_prep.py         # Training data preparation
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ hub.py               # Hugging Face Hub integration
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ usage.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ limits.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ notifications.py
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ middleware/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ auth.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ rate_limit.py
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ main.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_rag.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_agents.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_text2sql.py         # ‚≠ê NEW
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_finetune.py         # ‚≠ê NEW
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îÇ
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ routes/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ +page.svelte
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ +layout.svelte
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ login/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ projects/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ settings/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database/            # ‚≠ê NEW: DB management UI
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ finetune/            # ‚≠ê NEW: Fine-tuning UI
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ admin/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lib/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Chat/
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Sidebar/
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ AgentSelector/
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DebugPanel/
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ SQLResult/       # ‚≠ê NEW
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ChartView/       # ‚≠ê NEW
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ UsageDashboard/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ stores/
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ auth.ts
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ project.ts
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ chat.ts
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ client.ts
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ app.html
‚îÇ   ‚îú‚îÄ‚îÄ static/
‚îÇ   ‚îú‚îÄ‚îÄ svelte.config.js
‚îÇ   ‚îî‚îÄ‚îÄ package.json
‚îÇ
‚îú‚îÄ‚îÄ configs/
‚îÇ   ‚îú‚îÄ‚îÄ base.yaml
‚îÇ   ‚îú‚îÄ‚îÄ agents/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ general.yaml
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hr.yaml
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ legal.yaml
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ finance.yaml
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ data_analyst.yaml        # ‚≠ê NEW
‚îÇ   ‚îî‚îÄ‚îÄ databases/                   # ‚≠ê NEW
‚îÇ       ‚îî‚îÄ‚îÄ example_schema.yaml
‚îÇ
‚îú‚îÄ‚îÄ training/                        # ‚≠ê NEW: Fine-tuning scripts
‚îÇ   ‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ finetune_embedding.ipynb
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ finetune_classifier.ipynb
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ finetune_llm_lora.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ prepare_data.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train_embedding.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train_classifier.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ train_lora.py
‚îÇ   ‚îî‚îÄ‚îÄ data/
‚îÇ       ‚îî‚îÄ‚îÄ sample/
‚îÇ
‚îú‚îÄ‚îÄ docker/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.yml
‚îÇ   ‚îî‚îÄ‚îÄ docker-compose.dev.yml
‚îÇ
‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îî‚îÄ‚îÄ workflows/
‚îÇ       ‚îú‚îÄ‚îÄ ci.yml
‚îÇ       ‚îî‚îÄ‚îÄ deploy.yml
‚îÇ
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ API.md
‚îÇ   ‚îú‚îÄ‚îÄ DEPLOYMENT.md
‚îÇ   ‚îú‚îÄ‚îÄ AGENTS.md
‚îÇ   ‚îú‚îÄ‚îÄ TEXT2SQL.md                  # ‚≠ê NEW
‚îÇ   ‚îî‚îÄ‚îÄ FINETUNING.md                # ‚≠ê NEW
‚îÇ
‚îú‚îÄ‚îÄ Makefile
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ .env.example
```

---

## üìÖ Development Phases (Updated)

### Phase 1: Foundation (Week 1-2)
**Goal**: Basic working app with authentication

- [ ] Setup project structure
- [ ] Setup Hetzner VPS + Coolify
- [ ] Setup GitHub Actions CI/CD
- [ ] FastAPI backend skeleton
- [ ] SvelteKit frontend skeleton
- [ ] User authentication (register/login)
- [ ] Basic chat UI (no RAG yet)
- [ ] LiteLLM integration (single model)
- [ ] Docker containerization

**Deliverable**: User can login and chat with AI

---

### Phase 2: RAG Core (Week 3-4)
**Goal**: Document upload and RAG working

- [ ] Document upload API
- [ ] PDF/DOCX text extraction
- [ ] Text chunking (recursive)
- [ ] ChromaDB integration
- [ ] Embedding generation
- [ ] Basic retrieval (dense search)
- [ ] Source citations in responses
- [ ] Document management UI

**Deliverable**: User can upload docs and ask questions

---

### Phase 3: Agent System (Week 5-6)
**Goal**: Multi-agent with tools

- [ ] Agent base class
- [ ] Agent configuration loader (YAML)
- [ ] Agent execution engine
- [ ] Basic tools (search, summarize)
- [ ] Pre-built agents (General, HR, Legal)
- [ ] Agent selector UI
- [ ] Agent thinking display
- [ ] Tool execution visualization

**Deliverable**: User can select agents for different tasks

---

### Phase 4: Project System (Week 7)
**Goal**: Multi-project with isolated data

- [ ] Project CRUD API
- [ ] Per-project document storage
- [ ] Per-project conversations
- [ ] Project settings UI
- [ ] Project switching in sidebar
- [ ] Project-scoped RAG queries

**Deliverable**: User can organize work into projects

---

### Phase 5: Text-to-SQL ‚≠ê NEW (Week 8)
**Goal**: Query databases with natural language

- [ ] Database connection management
- [ ] Schema discovery & caching
- [ ] SQL generation with LLM
- [ ] SQL validation & safety checks
- [ ] Query execution (read-only)
- [ ] Result formatting (table, chart)
- [ ] Data Analyst agent
- [ ] Database settings UI

**Deliverable**: User can query their database using natural language

---

### Phase 6: Fine-tuning Module ‚≠ê NEW (Week 9-10)
**Goal**: Train custom models

- [ ] Training data preparation tools
- [ ] Embedding fine-tuning script
- [ ] Classifier fine-tuning script
- [ ] LLM LoRA fine-tuning script
- [ ] Hugging Face Hub integration
- [ ] Fine-tuning job management API
- [ ] Fine-tuning dashboard UI
- [ ] Integration with platform (use custom models)

**Deliverable**: User can fine-tune and deploy custom models

---

### Phase 7: Polish & Production (Week 11-12)
**Goal**: Production-ready features

- [ ] Usage tracking service
- [ ] User limits & quotas
- [ ] Rate limiting
- [ ] Usage dashboard UI
- [ ] Admin panel (full)
- [ ] Debug panel
- [ ] Error handling & retry
- [ ] Performance optimization
- [ ] Security audit
- [ ] Documentation

**Deliverable**: Ready for demo/production

---

### Phase 8: Advanced Features (Optional)
**Goal**: Impressive extras

- [ ] Hybrid search (Dense + BM25)
- [ ] Re-ranking
- [ ] Multi-model switching
- [ ] A/B model comparison
- [ ] Voice input (STT)
- [ ] Voice output (TTS)
- [ ] Team sharing
- [ ] Custom agent builder UI
- [ ] MongoDB support for Text-to-SQL
- [ ] Multimodal RAG (images, audio)

---

## üéì Skills Coverage (Updated)

| Job Requirement | Project Feature | Status |
|-----------------|-----------------|--------|
| **RAG Pipeline** | Document upload, embedding, retrieval | ‚úÖ |
| **Agentic AI** | Multi-agent system, tools, reasoning | ‚úÖ |
| **Fine-tuning LLMs** | Embedding, Classifier, LLM LoRA fine-tuning | ‚úÖ NEW |
| **Hugging Face** | Transformers, PEFT, Hub | ‚úÖ NEW |
| **Python Scientific** | NumPy, Pandas, Data processing | ‚úÖ |
| **RESTful APIs** | Full REST API | ‚úÖ |
| **MLOps** | Prometheus, W&B, model deployment | ‚úÖ |
| **CI/CD** | GitHub Actions | ‚úÖ |
| **Large-scale Data** | Document processing, SQL queries | ‚úÖ |
| **Data Analysis** | Text-to-SQL, visualization | ‚úÖ NEW |

### ‡∏Ñ‡∏£‡∏ö‡∏ó‡∏∏‡∏Å Requirements ‡∏Ç‡∏≠‡∏á Sciology ‚úÖ

---

## üí¨ Interview Talking Points (Updated)

### Elevator Pitch
> "‡∏ú‡∏°‡∏™‡∏£‡πâ‡∏≤‡∏á RAG Agent Platform ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô domain-agnostic template ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö multi-project ‡πÅ‡∏ï‡πà‡∏•‡∏∞ project ‡∏°‡∏µ isolated knowledge base ‡πÅ‡∏•‡∏∞‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡πà‡∏≠ database ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á ‡∏ú‡πà‡∏≤‡∏ô Text-to-SQL ‡∏ó‡∏µ‡πà query ‡∏î‡πâ‡∏ß‡∏¢‡∏†‡∏≤‡∏©‡∏≤‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥ ‡∏°‡∏µ pre-built agents ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö HR, Legal, Finance, Data Analysis ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ ‡∏£‡∏∞‡∏ö‡∏ö‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö fine-tuning ‡∏ó‡∏±‡πâ‡∏á embeddings, classifiers ‡πÅ‡∏•‡∏∞ LLM ‡∏î‡πâ‡∏ß‡∏¢ LoRA ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏±‡∏ö‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö domain ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ ‡πÉ‡∏ä‡πâ Hugging Face ecosystem ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ‡πÅ‡∏•‡∏∞‡∏°‡∏µ CI/CD pipeline ‡∏û‡∏£‡πâ‡∏≠‡∏° monitoring"

### Technical Deep-Dives

**Q: Fine-tuning ‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£‡πÑ‡∏î‡πâ‡∏ö‡πâ‡∏≤‡∏á?**
> "‡∏ú‡∏°‡∏ó‡∏≥ 3 ‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏£‡∏±‡∏ö: 
> 1) Fine-tune embeddings ‡∏î‡πâ‡∏ß‡∏¢ sentence-transformers ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á retrieval ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö domain ‡πÄ‡∏â‡∏û‡∏≤‡∏∞
> 2) Fine-tune classifier ‡∏î‡πâ‡∏ß‡∏¢ BERT ‡πÄ‡∏û‡∏∑‡πà‡∏≠ route queries ‡πÑ‡∏õ‡∏¢‡∏±‡∏á agent ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°
> 3) Fine-tune LLM ‡∏î‡πâ‡∏ß‡∏¢ QLoRA ‡∏ö‡∏ô Qwen/Llama ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡πÉ‡∏ô‡∏™‡πÑ‡∏ï‡∏•‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ ‡πÉ‡∏ä‡πâ Hugging Face Transformers ‡πÅ‡∏•‡∏∞ PEFT library ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î push model ‡∏Ç‡∏∂‡πâ‡∏ô Hub ‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢"

**Q: Text-to-SQL ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏¢‡∏±‡∏á‡πÑ‡∏á?**
> "‡∏ú‡∏°‡∏™‡πà‡∏á schema context (‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏≤‡∏£‡∏≤‡∏á, ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå, relationships) ‡πÉ‡∏´‡πâ LLM ‡∏û‡∏£‡πâ‡∏≠‡∏° query ‡∏†‡∏≤‡∏©‡∏≤‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥ LLM generate SQL ‡πÅ‡∏•‡πâ‡∏ß‡∏ú‡πà‡∏≤‡∏ô validator ‡∏ó‡∏µ‡πà check ‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô SELECT only, ‡πÑ‡∏°‡πà‡∏°‡∏µ destructive operations ‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô execute ‡πÉ‡∏ô sandbox ‡∏ó‡∏µ‡πà‡∏°‡∏µ timeout ‡πÅ‡∏•‡∏∞ row limit ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÄ‡∏õ‡πá‡∏ô table ‡∏´‡∏£‡∏∑‡∏≠ auto-generate chart"

**Q: RAG ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏¢‡∏±‡∏á‡πÑ‡∏á?**
> "‡πÉ‡∏ä‡πâ hybrid search ‡∏£‡∏ß‡∏° dense embeddings (multilingual-e5 ‡∏´‡∏£‡∏∑‡∏≠ fine-tuned) ‡∏Å‡∏±‡∏ö BM25 ‡πÅ‡∏•‡πâ‡∏ß fuse ‡∏î‡πâ‡∏ß‡∏¢ Reciprocal Rank Fusion ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ fine-tuned embeddings ‡∏ó‡∏µ‡πà train ‡∏ö‡∏ô domain data ‡πÑ‡∏î‡πâ ‡∏ó‡∏≥‡πÉ‡∏´‡πâ retrieval accuracy ‡∏™‡∏π‡∏á‡∏Ç‡∏∂‡πâ‡∏ô"

**Q: Production-ready ‡πÑ‡∏´‡∏°?**
> "‡∏°‡∏µ error handling ‡∏Ñ‡∏£‡∏ö, retry logic, rate limiting ‡∏ú‡πà‡∏≤‡∏ô LiteLLM, monitoring ‡∏î‡πâ‡∏ß‡∏¢ Prometheus, experiment tracking ‡∏î‡πâ‡∏ß‡∏¢ W&B, CI/CD ‡∏ó‡∏µ‡πà test ‡∏Å‡πà‡∏≠‡∏ô deploy ‡πÅ‡∏•‡∏∞‡∏°‡∏µ security features ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Text-to-SQL ‡πÄ‡∏ä‡πà‡∏ô read-only mode, query validation, sensitive data masking"

---

## üìé Appendix

### A. Environment Variables (Updated)

```env
# App
APP_NAME=RAG Agent Platform
APP_ENV=production
SECRET_KEY=your-secret-key

# Database (Internal)
DATABASE_URL=postgresql://user:pass@localhost:5432/ragagent

# LiteLLM
LITELLM_MASTER_KEY=sk-master-key
OPENAI_API_KEY=sk-xxx
ANTHROPIC_API_KEY=sk-xxx

# Embeddings
EMBEDDING_MODEL=intfloat/multilingual-e5-base
# Or fine-tuned: username/custom-e5-hr

# Hugging Face
HF_TOKEN=hf_xxx
HF_USERNAME=your-username

# Weights & Biases (optional)
WANDB_API_KEY=xxx

# Storage
UPLOAD_DIR=/data/uploads
CHROMA_DIR=/data/chroma
MODELS_DIR=/data/models

# Text-to-SQL
SQL_QUERY_TIMEOUT=30
SQL_MAX_ROWS=1000
```

### B. API Endpoints (Updated)

```
Auth
  POST   /api/auth/register
  POST   /api/auth/login
  POST   /api/auth/logout
  GET    /api/auth/me

Projects
  GET    /api/projects
  POST   /api/projects
  GET    /api/projects/{id}
  PUT    /api/projects/{id}
  DELETE /api/projects/{id}

Documents
  GET    /api/projects/{id}/documents
  POST   /api/projects/{id}/documents
  DELETE /api/projects/{id}/documents/{doc_id}

Chat
  POST   /api/projects/{id}/chat
  GET    /api/projects/{id}/conversations
  GET    /api/projects/{id}/conversations/{conv_id}

Agents
  GET    /api/agents
  GET    /api/agents/{id}

Database Connections (NEW)
  GET    /api/projects/{id}/databases
  POST   /api/projects/{id}/databases
  GET    /api/projects/{id}/databases/{db_id}/schema
  POST   /api/projects/{id}/databases/{db_id}/test
  DELETE /api/projects/{id}/databases/{db_id}
  POST   /api/projects/{id}/databases/{db_id}/query

Fine-tuning (NEW)
  GET    /api/finetune/jobs
  POST   /api/finetune/jobs
  GET    /api/finetune/jobs/{job_id}
  POST   /api/finetune/jobs/{job_id}/stop
  GET    /api/finetune/models
  POST   /api/finetune/models/{model_id}/deploy
  DELETE /api/finetune/models/{model_id}

Admin
  GET    /api/admin/users
  PUT    /api/admin/users/{id}
  GET    /api/admin/usage
  GET    /api/admin/finetune/jobs
```

### C. Docker Compose (Updated)

```yaml
version: '3.8'

services:
  app:
    build: .
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://postgres:postgres@db:5432/ragagent
      - LITELLM_URL=http://litellm:4000
      - HF_TOKEN=${HF_TOKEN}
    depends_on:
      - db
      - litellm
    volumes:
      - ./data:/data
      - ./models:/models

  litellm:
    image: ghcr.io/berriai/litellm:main-latest
    ports:
      - "4000:4000"
    environment:
      - LITELLM_MASTER_KEY=${LITELLM_MASTER_KEY}
      - UI_USERNAME=admin
      - UI_PASSWORD=${LITELLM_UI_PASSWORD}
    volumes:
      - ./litellm-config.yaml:/app/config.yaml

  db:
    image: postgres:15
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=ragagent
    volumes:
      - postgres_data:/var/lib/postgresql/data

  prometheus:
    image: prom/prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml

  # Optional: Ollama for local fine-tuned models
  ollama:
    image: ollama/ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]  # If GPU available

volumes:
  postgres_data:
  ollama_data:
```

### D. Training Requirements (NEW)

```txt
# training/requirements.txt
torch>=2.0.0
transformers>=4.36.0
sentence-transformers>=2.2.0
datasets>=2.16.0
peft>=0.7.0
trl>=0.7.0
bitsandbytes>=0.41.0
accelerate>=0.25.0
wandb>=0.16.0
huggingface_hub>=0.20.0
scikit-learn>=1.3.0
```

---

## ‚úÖ Ready to Start

- [ ] Create GitHub repository
- [ ] Setup Hetzner VPS
- [ ] Install Coolify
- [ ] Configure GitHub Actions
- [ ] Create Hugging Face account & token
- [ ] Begin Phase 1

---

## üìä Timeline Summary

| Phase | Week | Features |
|-------|------|----------|
| 1. Foundation | 1-2 | Auth, Chat, LiteLLM |
| 2. RAG Core | 3-4 | Documents, Embeddings, Retrieval |
| 3. Agent System | 5-6 | Multi-agent, Tools |
| 4. Project System | 7 | Multi-project, Isolation |
| 5. Text-to-SQL | 8 | Database queries ‚≠ê |
| 6. Fine-tuning | 9-10 | Custom models ‚≠ê |
| 7. Polish | 11-12 | Production-ready |

**Total: 12 weeks (3 months)**

---

*Document Version 2.0 - December 2024*
*Added: Fine-tuning Module, Text-to-SQL System*